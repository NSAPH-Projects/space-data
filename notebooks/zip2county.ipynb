{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for county aggregation\n",
    "\n",
    "def modify_year(year, tmp_df):\n",
    "    # Find the oldest county match for each zip\n",
    "    grouped_df = tmp_df.sort_values('year').groupby('zip').head(1)\n",
    "    # Update the year column\n",
    "    grouped_df['year'] = year\n",
    "    return grouped_df\n",
    "\n",
    "def county_aggregate(df, xwalk_path):\n",
    "    zip_county_xwalk = pd.read_csv(xwalk_path,\n",
    "                                   dtype={\"zip\": str, \"county\": str})\n",
    "    zip_county_xwalk[\"zip\"] = zip_county_xwalk[\"zip\"].astype(str).str.zfill(5)\n",
    "    zip_county_xwalk[\"county\"] = zip_county_xwalk[\"county\"].astype(str).str.zfill(5)\n",
    "    df[\"zip\"] = df[\"zip\"].astype(str).str.zfill(5)\n",
    "\n",
    "    xwalk_lst = [modify_year(year, zip_county_xwalk) for year in range(2000, 2010)]\n",
    "    # expanded xwalk df works with year+county matches\n",
    "    final_xwalk_df = pd.concat([zip_county_xwalk] + xwalk_lst, \n",
    "                               ignore_index=True)\n",
    "\n",
    "    # merging with full dataset\n",
    "    print('original number entries [ZIP code dataset]: ' + str(len(df)))\n",
    "    print('number of unique zips [zip dataset]: ' + str(len(df[\"zip\"].unique())))\n",
    "    df_mg = df.merge(final_xwalk_df, \n",
    "                    on=[\"zip\", \"year\"])\n",
    "    print('number of unique zips [county dataset]: ' + str(len(df_mg[\"zip\"].unique())))\n",
    "    df_filtered = df_mg.drop(columns=['zip', \n",
    "                                    'lat', \n",
    "                                    'lon', \n",
    "                                    'tot_ratio']) # don't need these cols\n",
    "    # Group by 'county' and 'year' and take the mean of the remaining columns\n",
    "    df_aggregated = df_filtered.groupby(['county', 'year'], as_index=False).mean()\n",
    "    df_aggregated[\"county\"] = df_aggregated[\"county\"].astype(str).str.zfill(5)\n",
    "    print('final number of entries [county dataset]: '+ str(len(df_aggregated)))\n",
    "    print('number of unique counties: ' + str(len(df_aggregated[\"county\"].unique())))\n",
    "\n",
    "    return df_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original number entries [ZIP code dataset]: 485126\n",
      "number of unique zips [zip dataset]: 28691\n",
      "number of unique zips [county dataset]: 28658\n",
      "final number of entries [county dataset]: 41580\n",
      "number of unique counties: 2470\n"
     ]
    }
   ],
   "source": [
    "# read in zip-level file\n",
    "\n",
    "zip_df = pd.read_parquet(\"../data_collections/sim_medicare/data.parquet\")\n",
    "xwalk_path = \"../data_collections/sim_medicare_county/zip2county_master_xwalk_2010_2023_tot_ratio_one2one.csv\"\n",
    "county_df = county_aggregate(zip_df, xwalk_path)\n",
    "county_df.index = county_df[\"county\"]\n",
    "county_df = county_df.drop([\"county\"], axis=1)\n",
    "\n",
    "# saving county dataset\n",
    "county_df.to_parquet(\"../data_collections/sim_medicare_county/data.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacedata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
